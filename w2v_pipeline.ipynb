{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text  target  \n",
       "0  Donald Trump just couldn t wish all Americans ...       0  \n",
       "1  House Intelligence Committee Chairman Devin Nu...       0  \n",
       "2  On Friday, it was revealed that former Milwauk...       0  \n",
       "3  On Christmas day, Donald Trump announced that ...       0  \n",
       "4  Pope Francis used his annual Christmas Day mes...       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake = pd.read_csv('data/Fake.csv')\n",
    "df_true = pd.read_csv('data/True.csv')\n",
    "df_fake['target'] = 0\n",
    "df_true['target'] = 1\n",
    "df = pd.concat([df_fake, df_true], ignore_index=True)\n",
    "df_text = df.drop(['subject', 'date'], axis=1)\n",
    "print(df_text.shape)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text_: str)->list:\n",
    "    text_ = text_.replace(\"\\n\", \" \") \n",
    "    tokenized_text = []\n",
    "    # Итерируемся по каждому предложению в фалйе\n",
    "    for i in sent_tokenize(text_):\n",
    "        temp = []\n",
    "        # Токенизируем предложения в слова\n",
    "        sentence = i.lower()\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "        sentence=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",sentence)\n",
    "        sentence=re.sub(\"(\\\\d|\\\\W)+\",\" \",sentence)\n",
    "        \n",
    "        for j in word_tokenize(sentence):\n",
    "            temp.append(j.lower())\n",
    "    \n",
    "        tokenized_text.append(temp)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building corpuses for model is: 100.00%\r"
     ]
    }
   ],
   "source": [
    "COUNT_TEXTS = len(df_text)\n",
    "all_texts = []\n",
    "for i, row in enumerate(df_text.values):\n",
    "    if i > COUNT_TEXTS:\n",
    "        break\n",
    "    \n",
    "    title_ = row[0]\n",
    "    text_ = row[1]\n",
    "        \n",
    "    title_list_ = tokenize(title_)\n",
    "    text_list_ = tokenize(text_)\n",
    "    \n",
    "    all_texts.extend(title_list_)\n",
    "    all_texts.extend(text_list_)\n",
    "    \n",
    "    print(f\"building corpuses for model is: {i / COUNT_TEXTS*100:.2f}%\", end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество предложений: 716816\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество предложений: {len(all_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tokenized texts\n",
    "with open('output/tokenize_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(all_texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tokenized texts\n",
    "with open('output/tokenize_texts.pkl', 'rb') as f:\n",
    "    loaded_tokenized_text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество предложений: 716816\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество предложений: {len(loaded_tokenized_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32257\n"
     ]
    }
   ],
   "source": [
    "model_w2v = Word2Vec(loaded_tokenized_text, min_count = 10, vector_size = 20, window = 10, seed=42)\n",
    "print(len(model_w2v.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444978149, 571038120)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.train(loaded_tokenized_text, total_examples=model_w2v.corpus_count, epochs=30, report_delay=0.1, compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраним модель W2V\n",
    "model_w2v.save('output/models/model_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузим модель W2V\n",
    "model_w2v = Word2Vec.load('output/models/model_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32257"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_w2v.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
